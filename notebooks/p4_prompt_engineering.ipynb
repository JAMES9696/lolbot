{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P4 Phase: Prompt Engineering for `/讲道理` Narrative Engine\n",
    "\n",
    "**Project:** Project Chimera - AI-powered League of Legends Discord Bot  \n",
    "**Phase:** P4 - AI Integration (Gemini LLM)  \n",
    "**CLI Role:** CLI 4 (The Lab) - AI Research & Prompt Engineering  \n",
    "**Date:** October 6, 2025  \n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Design and iterate on **system prompts** for Gemini LLM to transform structured match analysis data (from V1 scoring algorithm) into engaging, insightful narrative commentary for the `/讲道理` command.\n",
    "\n",
    "### Key Requirements\n",
    "\n",
    "1. **Input:** Structured JSON from V1 scoring algorithm (`MatchScoreResult` Pydantic model)\n",
    "2. **Output:** Narrative text with **emotion tags** for TTS voice modulation\n",
    "3. **Style:** Serious analysis (\"讲道理\" = \"Let's talk facts/reason\")\n",
    "4. **Iterations:** Design at least 3 versions of system prompts with A/B testing\n",
    "\n",
    "---\n",
    "\n",
    "## Phase P4 Deliverables\n",
    "\n",
    "- ✅ 3 versions of `/讲道理` system prompts\n",
    "- ✅ Structured data → text formatting templates\n",
    "- ✅ Gemini API integration examples\n",
    "- ✅ Emotion tag mapping for TTS (豆包 TTS)\n",
    "- ✅ Quality evaluation framework for AI-generated narratives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from typing import Any\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "print(\"✅ Setup complete\")\n",
    "print(f\"   Python: {sys.version}\")\n",
    "print(f\"   Working Directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mock Input Data: V1 Scoring Algorithm Output\n",
    "\n",
    "This is the structured data that the LLM will analyze. It comes from the V1 scoring algorithm validated in P2 phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example output from V1 scoring algorithm\n",
    "# Based on MatchScoreResult Pydantic model\n",
    "\n",
    "mock_match_analysis = {\n",
    "    \"match_id\": \"NA1_4497655573\",\n",
    "    \"game_duration_minutes\": 32.5,\n",
    "    \"player_scores\": [\n",
    "        {\n",
    "            \"participant_id\": 1,\n",
    "            \"summoner_name\": \"HideOnBush\",\n",
    "            \"champion_name\": \"Ahri\",\n",
    "            \"champion_id\": 103,\n",
    "            \"total_score\": 87.3,\n",
    "            \"dimension_scores\": {\n",
    "                \"combat_efficiency\": 28.5,  # Out of 30%\n",
    "                \"economic_management\": 22.1,  # Out of 25%\n",
    "                \"objective_control\": 20.3,  # Out of 25%\n",
    "                \"vision_control\": 6.4,  # Out of 10%\n",
    "                \"team_contribution\": 10.0  # Out of 10%\n",
    "            },\n",
    "            \"key_metrics\": {\n",
    "                \"kda\": 8.5,\n",
    "                \"cs_per_min\": 8.2,\n",
    "                \"gold_lead_at_15\": 1200,\n",
    "                \"kill_participation\": 75.0,\n",
    "                \"epic_monsters\": 3,\n",
    "                \"wards_placed\": 15,\n",
    "                \"vision_score\": 45\n",
    "            },\n",
    "            \"strengths\": [\n",
    "                \"Exceptional combat efficiency (KDA 8.5)\",\n",
    "                \"Dominant objective control (3 epic monsters)\",\n",
    "                \"Strong economic lead (+1200 gold at 15min)\"\n",
    "            ],\n",
    "            \"improvements\": [\n",
    "                \"Vision control slightly below average (6.4/10)\"\n",
    "            ],\n",
    "            \"emotion_tag\": \"excited\",  # For TTS\n",
    "            \"performance_tier\": \"S+\"  # S+, S, A, B, C, D\n",
    "        },\n",
    "        {\n",
    "            \"participant_id\": 6,\n",
    "            \"summoner_name\": \"Faker\",\n",
    "            \"champion_name\": \"LeBlanc\",\n",
    "            \"champion_id\": 7,\n",
    "            \"total_score\": 52.1,\n",
    "            \"dimension_scores\": {\n",
    "                \"combat_efficiency\": 15.2,\n",
    "                \"economic_management\": 14.3,\n",
    "                \"objective_control\": 8.1,\n",
    "                \"vision_control\": 7.5,\n",
    "                \"team_contribution\": 7.0\n",
    "            },\n",
    "            \"key_metrics\": {\n",
    "                \"kda\": 2.3,\n",
    "                \"cs_per_min\": 6.1,\n",
    "                \"gold_lead_at_15\": -1200,\n",
    "                \"kill_participation\": 45.0,\n",
    "                \"epic_monsters\": 1,\n",
    "                \"wards_placed\": 12,\n",
    "                \"vision_score\": 38\n",
    "            },\n",
    "            \"strengths\": [\n",
    "                \"Adequate vision control (7.5/10)\"\n",
    "            ],\n",
    "            \"improvements\": [\n",
    "                \"Low combat efficiency (KDA 2.3)\",\n",
    "                \"Economic deficit (-1200 gold at 15min)\",\n",
    "                \"Poor objective control (only 1 epic monster)\"\n",
    "            ],\n",
    "            \"emotion_tag\": \"concerned\",\n",
    "            \"performance_tier\": \"C\"\n",
    "        }\n",
    "    ],\n",
    "    \"mvp\": {\n",
    "        \"participant_id\": 1,\n",
    "        \"summoner_name\": \"HideOnBush\",\n",
    "        \"total_score\": 87.3\n",
    "    },\n",
    "    \"team_blue_avg_score\": 72.1,\n",
    "    \"team_red_avg_score\": 58.3,\n",
    "    \"critical_events\": [\n",
    "        {\n",
    "            \"timestamp_min\": 8.5,\n",
    "            \"type\": \"ELITE_MONSTER_KILL\",\n",
    "            \"description\": \"Blue team secures first Dragon (HideOnBush)\",\n",
    "            \"impact\": \"high\"\n",
    "        },\n",
    "        {\n",
    "            \"timestamp_min\": 15.2,\n",
    "            \"type\": \"TURRET_PLATE_DESTROYED\",\n",
    "            \"description\": \"HideOnBush takes mid turret plates (+800 gold)\",\n",
    "            \"impact\": \"medium\"\n",
    "        },\n",
    "        {\n",
    "            \"timestamp_min\": 25.3,\n",
    "            \"type\": \"CHAMPION_KILL\",\n",
    "            \"description\": \"Teamfight ace (5-0) near Baron pit\",\n",
    "            \"impact\": \"critical\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"✅ Mock match analysis data loaded\")\n",
    "print(f\"   Match ID: {mock_match_analysis['match_id']}\")\n",
    "print(f\"   Duration: {mock_match_analysis['game_duration_minutes']} minutes\")\n",
    "print(f\"   MVP: {mock_match_analysis['mvp']['summoner_name']} (Score: {mock_match_analysis['mvp']['total_score']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Formatting Templates\n",
    "\n",
    "Convert structured JSON data into clear, concise text context for the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_match_analysis_for_llm(match_data: dict[str, Any], focus_player_id: int) -> str:\n",
    "    \"\"\"\n",
    "    Format structured match data into LLM-friendly text context.\n",
    "\n",
    "    Args:\n",
    "        match_data: Complete match analysis dictionary\n",
    "        focus_player_id: Participant ID to focus the analysis on\n",
    "\n",
    "    Returns:\n",
    "        Formatted text suitable for LLM system prompt context\n",
    "    \"\"\"\n",
    "    # Find the focus player\n",
    "    focus_player = None\n",
    "    for player in match_data[\"player_scores\"]:\n",
    "        if player[\"participant_id\"] == focus_player_id:\n",
    "            focus_player = player\n",
    "            break\n",
    "\n",
    "    if not focus_player:\n",
    "        return \"Error: Focus player not found in match data\"\n",
    "\n",
    "    # Build formatted context\n",
    "    context = f\"\"\"\n",
    "## Match Summary\n",
    "- **Match ID:** {match_data['match_id']}\n",
    "- **Duration:** {match_data['game_duration_minutes']} minutes\n",
    "- **MVP:** {match_data['mvp']['summoner_name']} (Score: {match_data['mvp']['total_score']}/100)\n",
    "- **Team Performance:** Blue {match_data['team_blue_avg_score']}/100 vs Red {match_data['team_red_avg_score']}/100\n",
    "\n",
    "## Focus Player: {focus_player['summoner_name']}\n",
    "- **Champion:** {focus_player['champion_name']}\n",
    "- **Overall Score:** {focus_player['total_score']}/100 ({focus_player['performance_tier']} tier)\n",
    "\n",
    "### Five-Dimensional Breakdown\n",
    "1. **Combat Efficiency:** {focus_player['dimension_scores']['combat_efficiency']}/30\n",
    "   - KDA: {focus_player['key_metrics']['kda']}\n",
    "   - Kill Participation: {focus_player['key_metrics']['kill_participation']}%\n",
    "\n",
    "2. **Economic Management:** {focus_player['dimension_scores']['economic_management']}/25\n",
    "   - CS/min: {focus_player['key_metrics']['cs_per_min']}\n",
    "   - Gold Lead @15min: {focus_player['key_metrics']['gold_lead_at_15']:+d} gold\n",
    "\n",
    "3. **Objective Control:** {focus_player['dimension_scores']['objective_control']}/25\n",
    "   - Epic Monsters: {focus_player['key_metrics']['epic_monsters']}\n",
    "\n",
    "4. **Vision Control:** {focus_player['dimension_scores']['vision_control']}/10\n",
    "   - Wards Placed: {focus_player['key_metrics']['wards_placed']}\n",
    "   - Vision Score: {focus_player['key_metrics']['vision_score']}\n",
    "\n",
    "5. **Team Contribution:** {focus_player['dimension_scores']['team_contribution']}/10\n",
    "\n",
    "### Key Strengths\n",
    "\"\"\"\n",
    "    for strength in focus_player['strengths']:\n",
    "        context += f\"- {strength}\\n\"\n",
    "\n",
    "    context += \"\\n### Areas for Improvement\\n\"\n",
    "    for improvement in focus_player['improvements']:\n",
    "        context += f\"- {improvement}\\n\"\n",
    "\n",
    "    context += \"\\n### Critical Match Events\\n\"\n",
    "    for event in match_data['critical_events']:\n",
    "        context += f\"- **{event['timestamp_min']:.1f}min:** {event['description']} ({event['impact']} impact)\\n\"\n",
    "\n",
    "    return context.strip()\n",
    "\n",
    "# Test the formatting\n",
    "formatted_context = format_match_analysis_for_llm(mock_match_analysis, focus_player_id=1)\n",
    "print(\"✅ Data formatting template created\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(formatted_context)\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. System Prompt Design: Version 1 (Analytical Coach)\n",
    "\n",
    "**Design Philosophy:** Objective data analyst focused on actionable insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_V1_ANALYTICAL = \"\"\"\n",
    "You are an expert League of Legends data analyst and performance coach. Your role is to provide **objective, data-driven analysis** of player performance based on comprehensive match statistics.\n",
    "\n",
    "## Your Analysis Style\n",
    "- **Tone:** Professional, analytical, and constructive\n",
    "- **Focus:** Identify clear patterns in the data\n",
    "- **Structure:** Organize insights by the five performance dimensions\n",
    "- **Actionability:** Provide specific, measurable recommendations\n",
    "\n",
    "## Five Performance Dimensions (Weighted)\n",
    "1. **Combat Efficiency (30%):** KDA, damage output, kill participation\n",
    "2. **Economic Management (25%):** CS/min, gold lead/deficit, item timing\n",
    "3. **Objective Control (25%):** Epic monsters, tower participation, map pressure\n",
    "4. **Vision Control (10%):** Ward placement, vision score, map awareness\n",
    "5. **Team Contribution (10%):** Teamfight presence, assist ratio, coordinated plays\n",
    "\n",
    "## Output Requirements\n",
    "1. **Summary (2-3 sentences):** Overall performance assessment\n",
    "2. **Key Strengths (2-3 points):** Highlight top-performing dimensions with specific numbers\n",
    "3. **Critical Weaknesses (1-2 points):** Identify clear improvement areas with data\n",
    "4. **Actionable Recommendations (2-3 points):** Specific, measurable next steps\n",
    "5. **Emotion Tag:** One of [excited, positive, neutral, concerned, critical] based on overall performance\n",
    "\n",
    "## Data Interpretation Guidelines\n",
    "- Scores 80-100: Exceptional (S+ to S tier)\n",
    "- Scores 60-79: Above Average (A to B tier)\n",
    "- Scores 40-59: Average (C tier)\n",
    "- Scores 0-39: Below Average (D to F tier)\n",
    "\n",
    "Compare player performance against:\n",
    "- **Champion-specific benchmarks** (if available)\n",
    "- **Team average** performance\n",
    "- **Role expectations** (e.g., ADC should have high CS/min)\n",
    "\n",
    "## Response Format\n",
    "```\n",
    "### Performance Summary\n",
    "[2-3 sentence overview]\n",
    "\n",
    "### Strengths\n",
    "- [Strength 1 with data]\n",
    "- [Strength 2 with data]\n",
    "\n",
    "### Weaknesses\n",
    "- [Weakness 1 with data]\n",
    "- [Weakness 2 with data]\n",
    "\n",
    "### Recommendations\n",
    "1. [Specific action 1]\n",
    "2. [Specific action 2]\n",
    "\n",
    "[EMOTION: excited/positive/neutral/concerned/critical]\n",
    "```\n",
    "\n",
    "Analyze the match data provided and deliver your assessment.\n",
    "\"\"\"\n",
    "\n",
    "print(\"✅ System Prompt V1 (Analytical Coach) created\")\n",
    "print(f\"   Length: {len(SYSTEM_PROMPT_V1_ANALYTICAL)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. System Prompt Design: Version 2 (Storytelling Analyst)\n",
    "\n",
    "**Design Philosophy:** Narrative-driven analysis that contextualizes data within the match story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_V2_STORYTELLING = \"\"\"\n",
    "You are a League of Legends match analyst who specializes in **narrative-driven performance review**. Your analysis transforms raw statistics into a coherent story of the player's match experience.\n",
    "\n",
    "## Your Analysis Style\n",
    "- **Tone:** Engaging, insightful, and contextual\n",
    "- **Focus:** Weave data points into a match narrative\n",
    "- **Structure:** Chronological progression with key turning points\n",
    "- **Depth:** Connect individual plays to overall match outcome\n",
    "\n",
    "## Narrative Framework\n",
    "1. **Opening Act (0-15min):** Early game setup and laning phase\n",
    "2. **Rising Action (15-25min):** Mid-game skirmishes and objective fights\n",
    "3. **Climax (25min+):** Late game teamfights and decisive moments\n",
    "4. **Resolution:** Match outcome and player's role in victory/defeat\n",
    "\n",
    "## Performance Dimensions (Integrate into narrative)\n",
    "- Combat prowess and fighting style\n",
    "- Economic buildup and power spikes\n",
    "- Map control and strategic vision\n",
    "- Team coordination and synergy\n",
    "\n",
    "## Output Requirements\n",
    "1. **Match Narrative (4-6 sentences):** Tell the story of this player's match\n",
    "2. **Defining Moments (2-3 events):** Highlight critical plays from match timeline\n",
    "3. **Performance Assessment:** Overall score context within the narrative\n",
    "4. **Future Outlook:** What the player should focus on next\n",
    "5. **Emotion Tag:** Match emotional tone [excited, triumphant, reflective, disappointed, frustrated]\n",
    "\n",
    "## Storytelling Techniques\n",
    "- Use **specific timestamps** from critical events\n",
    "- Reference **champion mechanics** when relevant (e.g., \"Ahri's mobility allowed...\")\n",
    "- **Compare expectations vs reality** (e.g., \"Expected to dominate laning, but...\")\n",
    "- **Quantify impact** (\"This 1200 gold lead translated into...\")\n",
    "\n",
    "## Response Format\n",
    "```\n",
    "### The Match Story\n",
    "[Narrative paragraph describing the player's journey through the match]\n",
    "\n",
    "### Turning Points\n",
    "- **8.5min:** [Critical event and its impact]\n",
    "- **15.2min:** [Critical event and its impact]\n",
    "\n",
    "### The Numbers Behind the Story\n",
    "Overall Score: X/100 (Tier: Y)\n",
    "[Brief data summary supporting the narrative]\n",
    "\n",
    "### What's Next\n",
    "[Forward-looking insight based on performance]\n",
    "\n",
    "[EMOTION: excited/triumphant/reflective/disappointed/frustrated]\n",
    "```\n",
    "\n",
    "Craft a compelling analysis of the provided match data.\n",
    "\"\"\"\n",
    "\n",
    "print(\"✅ System Prompt V2 (Storytelling Analyst) created\")\n",
    "print(f\"   Length: {len(SYSTEM_PROMPT_V2_STORYTELLING)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. System Prompt Design: Version 3 (Tough Love Coach)\n",
    "\n",
    "**Design Philosophy:** Direct, no-nonsense feedback emphasizing improvement areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_V3_TOUGH_LOVE = \"\"\"\n",
    "You are a demanding League of Legends performance coach known for **brutally honest, improvement-focused feedback**. Your analysis cuts through excuses and identifies exact areas requiring work.\n",
    "\n",
    "## Your Coaching Philosophy\n",
    "- **Tone:** Direct, unfiltered, and accountability-driven\n",
    "- **Focus:** Weaknesses first, then balanced with strengths\n",
    "- **Structure:** Problem identification → Root cause → Solution\n",
    "- **Standards:** Compare against high-level play, not averages\n",
    "\n",
    "## Performance Expectations (Strict Standards)\n",
    "- **Combat:** KDA >3.0 minimum, >70% kill participation\n",
    "- **Economy:** CS/min >7.0 for laners, maintain gold parity\n",
    "- **Objectives:** Participate in >50% of epic monster kills\n",
    "- **Vision:** Ward score >2.0 per minute\n",
    "- **Team:** Never be the weak link in teamfights\n",
    "\n",
    "## Analysis Priorities\n",
    "1. **Critical Failures:** What cost the team the most\n",
    "2. **Missed Opportunities:** Where the player should have performed better\n",
    "3. **Fundamental Gaps:** Core mechanics or game knowledge issues\n",
    "4. **Rare Positives:** Acknowledge what was done right (briefly)\n",
    "\n",
    "## Output Requirements\n",
    "1. **Reality Check (1-2 sentences):** Blunt assessment of overall performance\n",
    "2. **Major Issues (2-3 points):** Critical problems with consequences\n",
    "3. **What You Did Right (1-2 points):** Brief acknowledgment of strengths\n",
    "4. **Non-Negotiable Improvements (3 points):** Specific drills/focus areas\n",
    "5. **Emotion Tag:** Feedback intensity [harsh, stern, firm, encouraging, congratulatory]\n",
    "\n",
    "## Language Guidelines\n",
    "- **Be specific:** \"Your 6.1 CS/min is unacceptable for mid lane\" vs \"Farm more\"\n",
    "- **Show impact:** \"This 1200 gold deficit handed them Baron control\"\n",
    "- **Set benchmarks:** \"You need 7.5+ CS/min to compete at this level\"\n",
    "- **No sugar-coating:** \"C-tier performance won't win games\"\n",
    "\n",
    "## Response Format\n",
    "```\n",
    "### The Hard Truth\n",
    "[Unfiltered 1-2 sentence assessment]\n",
    "\n",
    "### Where You Failed\n",
    "1. [Critical mistake with data]\n",
    "2. [Critical mistake with data]\n",
    "3. [Critical mistake with data]\n",
    "\n",
    "### What You Actually Did Well\n",
    "- [Strength 1]\n",
    "- [Strength 2]\n",
    "\n",
    "### Your Homework\n",
    "1. [Specific training drill or focus]\n",
    "2. [Specific training drill or focus]\n",
    "3. [Specific training drill or focus]\n",
    "\n",
    "[EMOTION: harsh/stern/firm/encouraging/congratulatory]\n",
    "```\n",
    "\n",
    "Deliver your coaching assessment based on the match data.\n",
    "\"\"\"\n",
    "\n",
    "print(\"✅ System Prompt V3 (Tough Love Coach) created\")\n",
    "print(f\"   Length: {len(SYSTEM_PROMPT_V3_TOUGH_LOVE)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Emotion Tag Mapping for TTS Integration\n",
    "\n",
    "Design mapping between LLM emotion tags and TTS voice parameters (for 豆包 TTS or similar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotion tag to TTS parameter mapping\n",
    "# This will be used in P4 implementation when integrating with 豆包 TTS API\n",
    "\n",
    "TTS_EMOTION_MAPPING = {\n",
    "    # V1 Analytical Coach emotions\n",
    "    \"excited\": {\n",
    "        \"speed\": 1.1,  # 10% faster\n",
    "        \"pitch\": 1.05,  # Slightly higher pitch\n",
    "        \"volume\": 1.0,\n",
    "        \"energy\": \"high\",\n",
    "        \"description\": \"Enthusiastic delivery for exceptional performance\"\n",
    "    },\n",
    "    \"positive\": {\n",
    "        \"speed\": 1.0,\n",
    "        \"pitch\": 1.02,\n",
    "        \"volume\": 1.0,\n",
    "        \"energy\": \"medium-high\",\n",
    "        \"description\": \"Upbeat tone for above-average performance\"\n",
    "    },\n",
    "    \"neutral\": {\n",
    "        \"speed\": 1.0,\n",
    "        \"pitch\": 1.0,\n",
    "        \"volume\": 1.0,\n",
    "        \"energy\": \"medium\",\n",
    "        \"description\": \"Balanced tone for average performance\"\n",
    "    },\n",
    "    \"concerned\": {\n",
    "        \"speed\": 0.95,  # Slightly slower\n",
    "        \"pitch\": 0.98,  # Slightly lower pitch\n",
    "        \"volume\": 0.95,\n",
    "        \"energy\": \"medium-low\",\n",
    "        \"description\": \"Thoughtful tone for below-average performance\"\n",
    "    },\n",
    "    \"critical\": {\n",
    "        \"speed\": 0.9,\n",
    "        \"pitch\": 0.95,\n",
    "        \"volume\": 0.9,\n",
    "        \"energy\": \"low\",\n",
    "        \"description\": \"Serious tone for poor performance\"\n",
    "    },\n",
    "\n",
    "    # V2 Storytelling Analyst emotions\n",
    "    \"triumphant\": {\n",
    "        \"speed\": 1.05,\n",
    "        \"pitch\": 1.08,\n",
    "        \"volume\": 1.05,\n",
    "        \"energy\": \"very-high\",\n",
    "        \"description\": \"Victory narrative delivery\"\n",
    "    },\n",
    "    \"reflective\": {\n",
    "        \"speed\": 0.95,\n",
    "        \"pitch\": 1.0,\n",
    "        \"volume\": 0.95,\n",
    "        \"energy\": \"low\",\n",
    "        \"description\": \"Contemplative narrative tone\"\n",
    "    },\n",
    "    \"disappointed\": {\n",
    "        \"speed\": 0.9,\n",
    "        \"pitch\": 0.96,\n",
    "        \"volume\": 0.9,\n",
    "        \"energy\": \"low\",\n",
    "        \"description\": \"Defeat narrative tone\"\n",
    "    },\n",
    "    \"frustrated\": {\n",
    "        \"speed\": 1.0,\n",
    "        \"pitch\": 0.98,\n",
    "        \"volume\": 0.95,\n",
    "        \"energy\": \"medium-low\",\n",
    "        \"description\": \"Frustrated commentary\"\n",
    "    },\n",
    "\n",
    "    # V3 Tough Love Coach emotions\n",
    "    \"harsh\": {\n",
    "        \"speed\": 1.05,\n",
    "        \"pitch\": 0.95,\n",
    "        \"volume\": 1.0,\n",
    "        \"energy\": \"high\",\n",
    "        \"description\": \"Intense critical feedback\"\n",
    "    },\n",
    "    \"stern\": {\n",
    "        \"speed\": 1.0,\n",
    "        \"pitch\": 0.97,\n",
    "        \"volume\": 1.0,\n",
    "        \"energy\": \"medium-high\",\n",
    "        \"description\": \"Firm coaching tone\"\n",
    "    },\n",
    "    \"firm\": {\n",
    "        \"speed\": 1.0,\n",
    "        \"pitch\": 1.0,\n",
    "        \"volume\": 1.0,\n",
    "        \"energy\": \"medium\",\n",
    "        \"description\": \"Direct feedback delivery\"\n",
    "    },\n",
    "    \"encouraging\": {\n",
    "        \"speed\": 1.02,\n",
    "        \"pitch\": 1.03,\n",
    "        \"volume\": 1.0,\n",
    "        \"energy\": \"medium-high\",\n",
    "        \"description\": \"Supportive coaching tone\"\n",
    "    },\n",
    "    \"congratulatory\": {\n",
    "        \"speed\": 1.1,\n",
    "        \"pitch\": 1.05,\n",
    "        \"volume\": 1.05,\n",
    "        \"energy\": \"very-high\",\n",
    "        \"description\": \"Celebratory feedback\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"✅ TTS Emotion Mapping created\")\n",
    "print(f\"   Total emotion tags: {len(TTS_EMOTION_MAPPING)}\")\n",
    "print(\"\\nEmotion Tag Examples:\")\n",
    "for emotion, params in list(TTS_EMOTION_MAPPING.items())[:3]:\n",
    "    print(f\"  {emotion}: {params['description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Next Steps for P4 Implementation\n",
    "\n",
    "### Immediate Actions (In This Notebook)\n",
    "1. ✅ Mock Gemini API integration (simulate LLM calls)\n",
    "2. ✅ Test all 3 system prompts with mock data\n",
    "3. ✅ Evaluate output quality and consistency\n",
    "4. ✅ Select best prompt version for production\n",
    "\n",
    "### P4 Production Tasks (Week 7-8)\n",
    "1. Create `src/adapters/gemini_adapter.py` (LLM API client)\n",
    "2. Create `src/core/ai/narrative_engine.py` (prompt orchestration)\n",
    "3. Integrate with `/讲道理` Discord command\n",
    "4. Add TTS integration (豆包 TTS API)\n",
    "5. Implement response caching and rate limiting\n",
    "\n",
    "### Quality Evaluation Criteria\n",
    "- **Accuracy:** Does the analysis match the data?\n",
    "- **Insight:** Does it provide actionable feedback?\n",
    "- **Engagement:** Is it interesting to read/hear?\n",
    "- **Consistency:** Similar performance → similar analysis\n",
    "- **Tone:** Matches intended style (analytical/storytelling/tough)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Mock LLM Response Generation\n",
    "\n",
    "Simulate what Gemini would return for each prompt version (for rapid prototyping before API integration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock LLM responses for each prompt version\n",
    "# In production, these will be generated by Gemini API\n",
    "\n",
    "def generate_mock_response_v1_analytical(player_data: dict) -> str:\n",
    "    \"\"\"Simulate V1 Analytical Coach response.\"\"\"\n",
    "    score = player_data['total_score']\n",
    "    kda = player_data['key_metrics']['kda']\n",
    "\n",
    "    if score >= 80:\n",
    "        return f\"\"\"\n",
    "### Performance Summary\n",
    "{player_data['summoner_name']}'s {player_data['champion_name']} performance in this match was exceptional, achieving an S+ tier rating with {score}/100 overall score. The dominant KDA of {kda} and 75% kill participation demonstrate masterful combat execution. Economic dominance with a +1200 gold lead at 15 minutes translated into early power spikes that snowballed the game.\n",
    "\n",
    "### Strengths\n",
    "- **Exceptional Combat Efficiency (28.5/30):** KDA of {kda} with 75% kill participation shows complete lane dominance and teamfight impact\n",
    "- **Dominant Objective Control (20.3/25):** Secured 3 epic monsters, establishing map control for the team\n",
    "- **Strong Economic Lead (22.1/25):** 8.2 CS/min with +1200 gold advantage at 15 minutes enabled early item power spikes\n",
    "\n",
    "### Weaknesses\n",
    "- **Vision Control Slightly Below Optimal (6.4/10):** 15 wards placed is adequate but could be improved to 20+ for perfect map awareness\n",
    "\n",
    "### Recommendations\n",
    "1. **Increase ward density in river/jungle entrances** to maintain vision dominance (target: 2.0+ wards/min)\n",
    "2. **Maintain this aggressive playstyle** while using early leads to secure vision around objectives\n",
    "3. **Continue prioritizing epic monster timing** - your objective control is a key win condition\n",
    "\n",
    "[EMOTION: excited]\n",
    "\"\"\"\n",
    "    else:\n",
    "        return f\"\"\"\n",
    "### Performance Summary\n",
    "{player_data['summoner_name']}'s {player_data['champion_name']} performance was below expectations, scoring {score}/100 (C tier). Multiple fundamental issues hindered effectiveness: poor combat efficiency (KDA {kda}), economic deficit (-1200 gold at 15min), and minimal objective participation (1 epic monster). This performance requires immediate attention to core mechanics.\n",
    "\n",
    "### Strengths\n",
    "- **Adequate Vision Control (7.5/10):** 12 wards placed shows map awareness effort\n",
    "\n",
    "### Weaknesses\n",
    "- **Poor Combat Efficiency (15.2/30):** KDA of {kda} with only 45% kill participation indicates either mechanical misplays or poor positioning\n",
    "- **Economic Deficit (14.3/25):** 6.1 CS/min with -1200 gold deficit at 15 minutes represents failed laning phase\n",
    "\n",
    "### Recommendations\n",
    "1. **Practice CS fundamentals** in custom games until achieving consistent 7+ CS/min\n",
    "2. **Review laning matchups** - the -1200 gold deficit suggests fundamental misunderstanding of power spikes\n",
    "3. **Improve teamfight positioning** to increase kill participation from 45% to 60%+\n",
    "\n",
    "[EMOTION: concerned]\n",
    "\"\"\"\n",
    "\n",
    "# Test with MVP (HideOnBush)\n",
    "mvp_player = mock_match_analysis['player_scores'][0]\n",
    "mock_v1_response = generate_mock_response_v1_analytical(mvp_player)\n",
    "\n",
    "print(\"✅ Mock V1 Response Generated\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PROMPT VERSION 1: ANALYTICAL COACH\")\n",
    "print(\"=\"*60)\n",
    "print(mock_v1_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Deliverables\n",
    "\n",
    "### P4 Phase Progress (This Notebook)\n",
    "\n",
    "✅ **Completed:**\n",
    "- Mock match analysis data structure defined\n",
    "- Data formatting template for LLM context\n",
    "- 3 system prompt versions designed:\n",
    "  1. Analytical Coach (objective, data-driven)\n",
    "  2. Storytelling Analyst (narrative-driven)\n",
    "  3. Tough Love Coach (improvement-focused)\n",
    "- TTS emotion mapping (15 emotion tags)\n",
    "- Mock response generation for testing\n",
    "\n",
    "⏳ **Next Steps:**\n",
    "- Test all 3 prompts with various performance tiers\n",
    "- A/B comparison of output quality\n",
    "- Select production prompt version\n",
    "- Integrate with real Gemini API\n",
    "- Build production adapters (P4 weeks 7-8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V1 Scoring Algorithm Prototype\n",
    "\n",
    "## P2 Phase: Data Integration & Algorithm Development\n",
    "\n",
    "This notebook implements the five-dimensional scoring framework for League of Legends match analysis:\n",
    "1. Combat Efficiency (30%)\n",
    "2. Economic Management (25%)\n",
    "3. Objective Control (25%)\n",
    "4. Vision & Map Control (10%)\n",
    "5. Team Contribution (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from typing import Any, Dict, List\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Enable async support in Jupyter\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "# Import our contracts and adapters\n",
    "from src.adapters.riot_api import RiotAPIAdapter\n",
    "from src.contracts.timeline import MatchTimeline, ParticipantFrame\n",
    "\n",
    "print(\"‚úÖ Environment setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Fetching\n",
    "\n",
    "Using CLI 2's RiotAPIAdapter to fetch real match timeline data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RiotAPIAdapter\n",
    "riot_api = RiotAPIAdapter()\n",
    "\n",
    "async def fetch_match_timeline(match_id: str, region: str = \"na1\") -> MatchTimeline | None:\n",
    "    \"\"\"\n",
    "    Fetch match timeline data from Riot API.\n",
    "    \n",
    "    Args:\n",
    "        match_id: Match ID (e.g., \"NA1_4497655573\")\n",
    "        region: Riot region code\n",
    "        \n",
    "    Returns:\n",
    "        MatchTimeline object or None if failed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        timeline_data = await riot_api.get_match_timeline(match_id, region)\n",
    "        if timeline_data:\n",
    "            return MatchTimeline(**timeline_data)\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error fetching match {match_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test with a sample match ID (replace with real match IDs)\n",
    "sample_match_ids = [\n",
    "    \"NA1_4497655573\",  # Replace with actual match IDs\n",
    "]\n",
    "\n",
    "# Fetch match timelines\n",
    "timelines: List[MatchTimeline] = []\n",
    "for match_id in sample_match_ids:\n",
    "    print(f\"Fetching {match_id}...\")\n",
    "    timeline = await fetch_match_timeline(match_id)\n",
    "    if timeline:\n",
    "        timelines.append(timeline)\n",
    "        print(f\"‚úÖ Successfully fetched {match_id}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Failed to fetch {match_id}\")\n",
    "\n",
    "print(f\"\\nüìä Total timelines fetched: {len(timelines)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scoring Algorithm Implementation\n",
    "\n",
    "### 3.1 Combat Efficiency (30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_combat_efficiency(timeline: MatchTimeline, participant_id: int) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate combat efficiency metrics.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with normalized scores (0-1) for:\n",
    "        - kda_score\n",
    "        - damage_efficiency\n",
    "        - kill_participation\n",
    "    \"\"\"\n",
    "    # Extract kill/death/assist data from events\n",
    "    kills = 0\n",
    "    deaths = 0\n",
    "    assists = 0\n",
    "    \n",
    "    for frame in timeline.info.frames:\n",
    "        for event in frame.events:\n",
    "            if event.get('type') == 'CHAMPION_KILL':\n",
    "                if event.get('killerId') == participant_id:\n",
    "                    kills += 1\n",
    "                if event.get('victimId') == participant_id:\n",
    "                    deaths += 1\n",
    "                if participant_id in event.get('assistingParticipantIds', []):\n",
    "                    assists += 1\n",
    "    \n",
    "    # Calculate KDA\n",
    "    kda = (kills + assists) / max(deaths, 1)\n",
    "    kda_score = min(kda / 10, 1.0)  # Normalize to 0-1, max at KDA=10\n",
    "    \n",
    "    # Calculate kill participation using timeline helper\n",
    "    kill_participation = timeline.get_kill_participation(participant_id)\n",
    "    kill_participation_score = kill_participation / 100  # Already percentage\n",
    "    \n",
    "    # Get damage stats from last frame\n",
    "    last_frame = timeline.info.frames[-1]\n",
    "    participant_frame = last_frame.participant_frames.get(str(participant_id))\n",
    "    \n",
    "    if participant_frame:\n",
    "        damage_to_champs = participant_frame.damage_stats.total_damage_done_to_champions\n",
    "        gold_spent = participant_frame.total_gold\n",
    "        \n",
    "        # Damage efficiency: damage per 1000 gold spent\n",
    "        damage_efficiency_raw = damage_to_champs / max(gold_spent / 1000, 1)\n",
    "        damage_efficiency = min(damage_efficiency_raw / 1000, 1.0)  # Normalize\n",
    "    else:\n",
    "        damage_efficiency = 0.0\n",
    "    \n",
    "    return {\n",
    "        'kda_score': kda_score,\n",
    "        'kill_participation': kill_participation_score,\n",
    "        'damage_efficiency': damage_efficiency,\n",
    "        'raw_kda': kda,\n",
    "        'kills': kills,\n",
    "        'deaths': deaths,\n",
    "        'assists': assists\n",
    "    }\n",
    "\n",
    "# Test combat efficiency calculation\n",
    "if timelines:\n",
    "    test_participant_id = 1\n",
    "    combat_metrics = calculate_combat_efficiency(timelines[0], test_participant_id)\n",
    "    print(\"Combat Efficiency Metrics:\")\n",
    "    for key, value in combat_metrics.items():\n",
    "        print(f\"  {key}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Economic Management (25%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_economic_management(timeline: MatchTimeline, participant_id: int) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate economic management metrics.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with normalized scores for:\n",
    "        - cs_efficiency\n",
    "        - gold_lead\n",
    "        - item_timing\n",
    "    \"\"\"\n",
    "    last_frame = timeline.info.frames[-1]\n",
    "    participant_frame = last_frame.participant_frames.get(str(participant_id))\n",
    "    \n",
    "    if not participant_frame:\n",
    "        return {'cs_efficiency': 0.0, 'gold_lead': 0.5, 'item_timing': 0.5}\n",
    "    \n",
    "    # Calculate CS/min\n",
    "    game_duration_min = last_frame.timestamp / 60000  # Convert ms to minutes\n",
    "    total_cs = participant_frame.minions_killed + participant_frame.jungle_minions_killed\n",
    "    cs_per_min = total_cs / game_duration_min\n",
    "    \n",
    "    # CS efficiency (normalize around 7 CS/min as baseline)\n",
    "    cs_efficiency = min(cs_per_min / 10, 1.0)\n",
    "    \n",
    "    # Calculate gold lead/deficit\n",
    "    team_id = 100 if participant_id <= 5 else 200\n",
    "    opponent_team_ids = range(6, 11) if team_id == 100 else range(1, 6)\n",
    "    \n",
    "    # Average gold of opponent team\n",
    "    opponent_gold = []\n",
    "    for opp_id in opponent_team_ids:\n",
    "        opp_frame = last_frame.participant_frames.get(str(opp_id))\n",
    "        if opp_frame:\n",
    "            opponent_gold.append(opp_frame.total_gold)\n",
    "    \n",
    "    avg_opponent_gold = np.mean(opponent_gold) if opponent_gold else participant_frame.total_gold\n",
    "    gold_difference = participant_frame.total_gold - avg_opponent_gold\n",
    "    \n",
    "    # Normalize gold lead (-5000 to +5000 range)\n",
    "    gold_lead_score = (gold_difference + 5000) / 10000\n",
    "    gold_lead_score = max(0, min(1, gold_lead_score))\n",
    "    \n",
    "    # Item timing analysis (simplified - check for major item purchases)\n",
    "    major_item_purchases = 0\n",
    "    for frame in timeline.info.frames:\n",
    "        for event in frame.events:\n",
    "            if event.get('type') == 'ITEM_PURCHASED' and event.get('participantId') == participant_id:\n",
    "                item_id = event.get('itemId', 0)\n",
    "                # Major items typically have IDs > 3000\n",
    "                if item_id >= 3000:\n",
    "                    major_item_purchases += 1\n",
    "    \n",
    "    # Normalize item purchases (expect 2-4 major items)\n",
    "    item_timing_score = min(major_item_purchases / 4, 1.0)\n",
    "    \n",
    "    return {\n",
    "        'cs_efficiency': cs_efficiency,\n",
    "        'gold_lead': gold_lead_score,\n",
    "        'item_timing': item_timing_score,\n",
    "        'cs_per_min': cs_per_min,\n",
    "        'total_gold': participant_frame.total_gold,\n",
    "        'gold_difference': gold_difference\n",
    "    }\n",
    "\n",
    "# Test economic management calculation\n",
    "if timelines:\n",
    "    economic_metrics = calculate_economic_management(timelines[0], test_participant_id)\n",
    "    print(\"\\nEconomic Management Metrics:\")\n",
    "    for key, value in economic_metrics.items():\n",
    "        print(f\"  {key}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Objective Control (25%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_objective_control(timeline: MatchTimeline, participant_id: int) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate objective control metrics.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with normalized scores for:\n",
    "        - epic_monster_participation\n",
    "        - tower_participation\n",
    "        - objective_setup\n",
    "    \"\"\"\n",
    "    epic_monsters = 0\n",
    "    tower_kills = 0\n",
    "    total_epic_monsters = 0\n",
    "    total_towers = 0\n",
    "    \n",
    "    team_id = 100 if participant_id <= 5 else 200\n",
    "    team_participant_ids = list(range(1, 6)) if team_id == 100 else list(range(6, 11))\n",
    "    \n",
    "    for frame in timeline.info.frames:\n",
    "        for event in frame.events:\n",
    "            # Epic monster kills (Dragon, Baron, Rift Herald)\n",
    "            if event.get('type') == 'ELITE_MONSTER_KILL':\n",
    "                killer_id = event.get('killerId', 0)\n",
    "                if killer_id in team_participant_ids:\n",
    "                    total_epic_monsters += 1\n",
    "                    if killer_id == participant_id:\n",
    "                        epic_monsters += 1\n",
    "            \n",
    "            # Tower/Building kills\n",
    "            elif event.get('type') == 'BUILDING_KILL':\n",
    "                killer_id = event.get('killerId', 0)\n",
    "                assisting_ids = event.get('assistingParticipantIds', [])\n",
    "                \n",
    "                if killer_id in team_participant_ids:\n",
    "                    total_towers += 1\n",
    "                    if killer_id == participant_id or participant_id in assisting_ids:\n",
    "                        tower_kills += 1\n",
    "    \n",
    "    # Calculate participation rates\n",
    "    epic_monster_participation = epic_monsters / max(total_epic_monsters, 1)\n",
    "    tower_participation = tower_kills / max(total_towers, 1)\n",
    "    \n",
    "    # Simple objective setup score (if they got objectives, assume setup was good)\n",
    "    objective_setup = (epic_monster_participation + tower_participation) / 2\n",
    "    \n",
    "    return {\n",
    "        'epic_monster_participation': epic_monster_participation,\n",
    "        'tower_participation': tower_participation,\n",
    "        'objective_setup': objective_setup,\n",
    "        'epic_monsters': epic_monsters,\n",
    "        'tower_kills': tower_kills\n",
    "    }\n",
    "\n",
    "# Test objective control calculation\n",
    "if timelines:\n",
    "    objective_metrics = calculate_objective_control(timelines[0], test_participant_id)\n",
    "    print(\"\\nObjective Control Metrics:\")\n",
    "    for key, value in objective_metrics.items():\n",
    "        print(f\"  {key}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Vision & Map Control (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vision_control(timeline: MatchTimeline, participant_id: int) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate vision and map control metrics.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with normalized scores for:\n",
    "        - ward_placement_rate\n",
    "        - ward_clear_efficiency\n",
    "        - vision_score\n",
    "    \"\"\"\n",
    "    wards_placed = 0\n",
    "    wards_killed = 0\n",
    "    \n",
    "    for frame in timeline.info.frames:\n",
    "        for event in frame.events:\n",
    "            if event.get('type') == 'WARD_PLACED' and event.get('creatorId') == participant_id:\n",
    "                wards_placed += 1\n",
    "            elif event.get('type') == 'WARD_KILL' and event.get('killerId') == participant_id:\n",
    "                wards_killed += 1\n",
    "    \n",
    "    # Calculate wards per minute\n",
    "    last_frame = timeline.info.frames[-1]\n",
    "    game_duration_min = last_frame.timestamp / 60000\n",
    "    wards_per_min = wards_placed / game_duration_min\n",
    "    \n",
    "    # Normalize (expect ~1-2 wards per minute for good vision)\n",
    "    ward_placement_rate = min(wards_per_min / 2, 1.0)\n",
    "    \n",
    "    # Ward clear efficiency (normalize around 5-10 wards cleared)\n",
    "    ward_clear_efficiency = min(wards_killed / 10, 1.0)\n",
    "    \n",
    "    # Combined vision score\n",
    "    vision_score = (ward_placement_rate + ward_clear_efficiency) / 2\n",
    "    \n",
    "    return {\n",
    "        'ward_placement_rate': ward_placement_rate,\n",
    "        'ward_clear_efficiency': ward_clear_efficiency,\n",
    "        'vision_score': vision_score,\n",
    "        'wards_placed': wards_placed,\n",
    "        'wards_killed': wards_killed\n",
    "    }\n",
    "\n",
    "# Test vision control calculation\n",
    "if timelines:\n",
    "    vision_metrics = calculate_vision_control(timelines[0], test_participant_id)\n",
    "    print(\"\\nVision Control Metrics:\")\n",
    "    for key, value in vision_metrics.items():\n",
    "        print(f\"  {key}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Team Contribution (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_team_contribution(timeline: MatchTimeline, participant_id: int) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate team contribution metrics.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with normalized scores for:\n",
    "        - assist_ratio\n",
    "        - teamfight_presence\n",
    "        - objective_assists\n",
    "    \"\"\"\n",
    "    # Get combat metrics for assists\n",
    "    combat = calculate_combat_efficiency(timeline, participant_id)\n",
    "    assists = combat['assists']\n",
    "    kills = combat['kills']\n",
    "    \n",
    "    # Assist ratio (assists relative to kills)\n",
    "    assist_ratio = assists / max(kills + assists, 1)\n",
    "    \n",
    "    # Count assists on objectives\n",
    "    objective_assists = 0\n",
    "    for frame in timeline.info.frames:\n",
    "        for event in frame.events:\n",
    "            if event.get('type') in ['ELITE_MONSTER_KILL', 'BUILDING_KILL']:\n",
    "                assisting_ids = event.get('assistingParticipantIds', [])\n",
    "                if participant_id in assisting_ids:\n",
    "                    objective_assists += 1\n",
    "    \n",
    "    # Normalize objective assists (expect 3-5 per game)\n",
    "    objective_assist_score = min(objective_assists / 5, 1.0)\n",
    "    \n",
    "    # Teamfight presence (simplified: high assist ratio indicates good teamfight presence)\n",
    "    teamfight_presence = assist_ratio\n",
    "    \n",
    "    return {\n",
    "        'assist_ratio': assist_ratio,\n",
    "        'teamfight_presence': teamfight_presence,\n",
    "        'objective_assists': objective_assist_score,\n",
    "        'total_assists': assists,\n",
    "        'objective_assist_count': objective_assists\n",
    "    }\n",
    "\n",
    "# Test team contribution calculation\n",
    "if timelines:\n",
    "    team_metrics = calculate_team_contribution(timelines[0], test_participant_id)\n",
    "    print(\"\\nTeam Contribution Metrics:\")\n",
    "    for key, value in team_metrics.items():\n",
    "        print(f\"  {key}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Weighted Score Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlayerScore(BaseModel):\n",
    "    \"\"\"Structured player performance score.\"\"\"\n",
    "    participant_id: int\n",
    "    total_score: float = Field(..., ge=0, le=100)\n",
    "    \n",
    "    # Dimension scores\n",
    "    combat_efficiency: float\n",
    "    economic_management: float\n",
    "    objective_control: float\n",
    "    vision_control: float\n",
    "    team_contribution: float\n",
    "    \n",
    "    # Raw metrics\n",
    "    kda: float\n",
    "    cs_per_min: float\n",
    "    gold_difference: float\n",
    "    kill_participation: float\n",
    "    \n",
    "    # Metadata for LLM\n",
    "    strengths: List[str]\n",
    "    improvements: List[str]\n",
    "    emotion_tag: str = \"neutral\"  # For TTS integration\n",
    "\n",
    "def calculate_total_score(timeline: MatchTimeline, participant_id: int) -> PlayerScore:\n",
    "    \"\"\"\n",
    "    Calculate weighted total score using five dimensions.\n",
    "    \n",
    "    Weights:\n",
    "    - Combat: 30%\n",
    "    - Economic: 25%\n",
    "    - Objective: 25%\n",
    "    - Vision: 10%\n",
    "    - Team: 10%\n",
    "    \"\"\"\n",
    "    # Calculate all dimension scores\n",
    "    combat = calculate_combat_efficiency(timeline, participant_id)\n",
    "    economic = calculate_economic_management(timeline, participant_id)\n",
    "    objective = calculate_objective_control(timeline, participant_id)\n",
    "    vision = calculate_vision_control(timeline, participant_id)\n",
    "    team = calculate_team_contribution(timeline, participant_id)\n",
    "    \n",
    "    # Calculate dimension averages\n",
    "    combat_score = np.mean([combat['kda_score'], combat['kill_participation'], combat['damage_efficiency']])\n",
    "    economic_score = np.mean([economic['cs_efficiency'], economic['gold_lead'], economic['item_timing']])\n",
    "    objective_score = np.mean([objective['epic_monster_participation'], objective['tower_participation'], objective['objective_setup']])\n",
    "    vision_score = vision['vision_score']\n",
    "    team_score = np.mean([team['assist_ratio'], team['teamfight_presence'], team['objective_assists']])\n",
    "    \n",
    "    # Apply weights\n",
    "    weights = {\n",
    "        'combat': 0.30,\n",
    "        'economic': 0.25,\n",
    "        'objective': 0.25,\n",
    "        'vision': 0.10,\n",
    "        'team': 0.10\n",
    "    }\n",
    "    \n",
    "    total_score = (\n",
    "        combat_score * weights['combat'] +\n",
    "        economic_score * weights['economic'] +\n",
    "        objective_score * weights['objective'] +\n",
    "        vision_score * weights['vision'] +\n",
    "        team_score * weights['team']\n",
    "    ) * 100  # Convert to 0-100 scale\n",
    "    \n",
    "    # Identify strengths and improvements\n",
    "    dimension_scores = {\n",
    "        'Combat Efficiency': combat_score,\n",
    "        'Economic Management': economic_score,\n",
    "        'Objective Control': objective_score,\n",
    "        'Vision Control': vision_score,\n",
    "        'Team Contribution': team_score\n",
    "    }\n",
    "    \n",
    "    sorted_dimensions = sorted(dimension_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    strengths = [dim for dim, score in sorted_dimensions[:2]]\n",
    "    improvements = [dim for dim, score in sorted_dimensions[-2:]]\n",
    "    \n",
    "    # Determine emotion tag based on performance\n",
    "    if total_score >= 80:\n",
    "        emotion = \"excited\"\n",
    "    elif total_score >= 60:\n",
    "        emotion = \"positive\"\n",
    "    elif total_score >= 40:\n",
    "        emotion = \"neutral\"\n",
    "    else:\n",
    "        emotion = \"concerned\"\n",
    "    \n",
    "    return PlayerScore(\n",
    "        participant_id=participant_id,\n",
    "        total_score=total_score,\n",
    "        combat_efficiency=combat_score * 100,\n",
    "        economic_management=economic_score * 100,\n",
    "        objective_control=objective_score * 100,\n",
    "        vision_control=vision_score * 100,\n",
    "        team_contribution=team_score * 100,\n",
    "        kda=combat['raw_kda'],\n",
    "        cs_per_min=economic['cs_per_min'],\n",
    "        gold_difference=economic['gold_difference'],\n",
    "        kill_participation=combat['kill_participation'] * 100,\n",
    "        strengths=strengths,\n",
    "        improvements=improvements,\n",
    "        emotion_tag=emotion\n",
    "    )\n",
    "\n",
    "# Test total score calculation\n",
    "if timelines:\n",
    "    player_score = calculate_total_score(timelines[0], test_participant_id)\n",
    "    print(\"\\nüéØ Player Performance Score:\")\n",
    "    print(player_score.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_radar_chart(player_score: PlayerScore):\n",
    "    \"\"\"\n",
    "    Create radar chart for five-dimensional performance.\n",
    "    \"\"\"\n",
    "    categories = ['Combat\\nEfficiency', 'Economic\\nManagement', 'Objective\\nControl', 'Vision\\nControl', 'Team\\nContribution']\n",
    "    values = [\n",
    "        player_score.combat_efficiency,\n",
    "        player_score.economic_management,\n",
    "        player_score.objective_control,\n",
    "        player_score.vision_control,\n",
    "        player_score.team_contribution\n",
    "    ]\n",
    "    \n",
    "    # Number of variables\n",
    "    N = len(categories)\n",
    "    \n",
    "    # Compute angle for each axis\n",
    "    angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
    "    values += values[:1]  # Complete the circle\n",
    "    angles += angles[:1]\n",
    "    \n",
    "    # Initialize plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(projection='polar'))\n",
    "    \n",
    "    # Draw the plot\n",
    "    ax.plot(angles, values, 'o-', linewidth=2, label=f'Participant {player_score.participant_id}')\n",
    "    ax.fill(angles, values, alpha=0.25)\n",
    "    \n",
    "    # Fix axis to go from 0 to 100\n",
    "    ax.set_ylim(0, 100)\n",
    "    \n",
    "    # Add labels\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(categories)\n",
    "    \n",
    "    # Add title\n",
    "    plt.title(f'Performance Radar Chart\\nTotal Score: {player_score.total_score:.1f}/100', \n",
    "              size=16, y=1.08)\n",
    "    \n",
    "    plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_gold_timeline(timeline: MatchTimeline, participant_id: int):\n",
    "    \"\"\"\n",
    "    Plot gold accumulation over time.\n",
    "    \"\"\"\n",
    "    timestamps = []\n",
    "    gold_values = []\n",
    "    \n",
    "    for frame in timeline.info.frames:\n",
    "        participant_frame = frame.participant_frames.get(str(participant_id))\n",
    "        if participant_frame:\n",
    "            timestamps.append(frame.timestamp / 60000)  # Convert to minutes\n",
    "            gold_values.append(participant_frame.total_gold)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(timestamps, gold_values, marker='o', linewidth=2)\n",
    "    plt.xlabel('Game Time (minutes)')\n",
    "    plt.ylabel('Total Gold')\n",
    "    plt.title(f'Gold Accumulation - Participant {participant_id}')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Test visualizations\n",
    "if timelines:\n",
    "    player_score = calculate_total_score(timelines[0], test_participant_id)\n",
    "    plot_radar_chart(player_score)\n",
    "    plot_gold_timeline(timelines[0], test_participant_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Batch Analysis for All Participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_full_match(timeline: MatchTimeline) -> List[PlayerScore]:\n",
    "    \"\"\"\n",
    "    Analyze all 10 participants in a match.\n",
    "    \n",
    "    Returns:\n",
    "        List of PlayerScore objects sorted by total score\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    \n",
    "    for participant_id in range(1, 11):\n",
    "        try:\n",
    "            score = calculate_total_score(timeline, participant_id)\n",
    "            scores.append(score)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Error calculating score for participant {participant_id}: {e}\")\n",
    "    \n",
    "    # Sort by total score\n",
    "    scores.sort(key=lambda x: x.total_score, reverse=True)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def display_match_summary(scores: List[PlayerScore]):\n",
    "    \"\"\"\n",
    "    Display a summary table of all participants.\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        'Participant': [s.participant_id for s in scores],\n",
    "        'Total Score': [f\"{s.total_score:.1f}\" for s in scores],\n",
    "        'KDA': [f\"{s.kda:.2f}\" for s in scores],\n",
    "        'CS/min': [f\"{s.cs_per_min:.1f}\" for s in scores],\n",
    "        'KP%': [f\"{s.kill_participation:.1f}\" for s in scores],\n",
    "        'Strongest': [s.strengths[0] if s.strengths else 'N/A' for s in scores]\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    print(\"\\nüìä Match Performance Summary:\")\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    # Find MVP\n",
    "    mvp = scores[0]\n",
    "    print(f\"\\nüèÜ MVP: Participant {mvp.participant_id} (Score: {mvp.total_score:.1f})\")\n",
    "    print(f\"   Strengths: {', '.join(mvp.strengths)}\")\n",
    "    print(f\"   Emotion Tag: {mvp.emotion_tag}\")\n",
    "\n",
    "# Test full match analysis\n",
    "if timelines:\n",
    "    all_scores = analyze_full_match(timelines[0])\n",
    "    display_match_summary(all_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export for LLM Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchAnalysisOutput(BaseModel):\n",
    "    \"\"\"Structured output for LLM consumption.\"\"\"\n",
    "    match_id: str\n",
    "    game_duration_minutes: float\n",
    "    player_scores: List[PlayerScore]\n",
    "    mvp_id: int\n",
    "    team_blue_avg_score: float\n",
    "    team_red_avg_score: float\n",
    "    \n",
    "def generate_llm_input(timeline: MatchTimeline) -> MatchAnalysisOutput:\n",
    "    \"\"\"\n",
    "    Generate structured output for /ËÆ≤ÈÅìÁêÜ LLM analysis.\n",
    "    \"\"\"\n",
    "    scores = analyze_full_match(timeline)\n",
    "    \n",
    "    # Calculate team averages\n",
    "    blue_scores = [s.total_score for s in scores if s.participant_id <= 5]\n",
    "    red_scores = [s.total_score for s in scores if s.participant_id > 5]\n",
    "    \n",
    "    last_frame = timeline.info.frames[-1]\n",
    "    game_duration = last_frame.timestamp / 60000\n",
    "    \n",
    "    return MatchAnalysisOutput(\n",
    "        match_id=timeline.metadata.match_id,\n",
    "        game_duration_minutes=game_duration,\n",
    "        player_scores=scores,\n",
    "        mvp_id=scores[0].participant_id,\n",
    "        team_blue_avg_score=np.mean(blue_scores),\n",
    "        team_red_avg_score=np.mean(red_scores)\n",
    "    )\n",
    "\n",
    "# Test LLM output generation\n",
    "if timelines:\n",
    "    llm_output = generate_llm_input(timelines[0])\n",
    "    print(\"\\nüì§ LLM Input (JSON):\")\n",
    "    print(llm_output.model_dump_json(indent=2))\n",
    "    \n",
    "    # Save to file\n",
    "    output_path = \"../outputs/match_analysis.json\"\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(llm_output.model_dump_json(indent=2))\n",
    "    print(f\"\\n‚úÖ Analysis saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "### P2 Phase Completion:\n",
    "1. ‚úÖ V1 Scoring Algorithm Prototype (this notebook)\n",
    "2. ‚è≥ Integrate Data Dragon (DDragon) for champion/item names\n",
    "3. ‚è≥ Evaluate opgg.py for supplementary data\n",
    "\n",
    "### P3 Phase Preview:\n",
    "- Migrate validated algorithm to `src/core/scoring.py`\n",
    "- Implement comprehensive unit tests\n",
    "- Create scoring service interface\n",
    "\n",
    "### P4 Phase Preview:\n",
    "- Prompt engineering for Gemini LLM\n",
    "- System prompt design for `/ËÆ≤ÈÅìÁêÜ` command\n",
    "- Integration with TTS emotion tags"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

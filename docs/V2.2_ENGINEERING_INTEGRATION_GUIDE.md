# V2.2 Personalization Feature - Engineering Integration Guide

**Author**: CLI 4 (The Lab)
**Date**: 2025-10-06
**Target Audience**: CLI 2 (Backend), CLI 1 (Frontend)
**Status**: ‚úÖ Production Ready
**Research Foundation**: `notebooks/v2.2_personalization.ipynb`

---

## üìã Table of Contents

1. [Feature Overview](#feature-overview)
2. [Architecture Diagram](#architecture-diagram)
3. [Data Flow](#data-flow)
4. [Integration Tasks](#integration-tasks)
5. [Testing Strategy](#testing-strategy)
6. [Rollout Plan](#rollout-plan)
7. [Success Criteria](#success-criteria)
8. [Handoff Checklist](#handoff-checklist)

---

## Feature Overview

### V2.2 Core Value Proposition

**Personalization** enables "ÂçÉ‰∫∫ÂçÉÈù¢" (one thousand faces) customization of prescriptive analysis based on:

1. **User Preferences** (explicit via `/settings`):
   - Analysis tone: competitive vs casual
   - Primary role preference

2. **Performance Trends** (inferred from history):
   - Persistent weak dimensions (e.g., Vision low in 75% of matches)
   - Average scores across dimensions

3. **Player Classification** (auto-detected):
   - Skill level: beginner / intermediate / advanced
   - Player type: casual / competitive

### Key Benefits

- **+15-20pp improvement** in "Helpfulness" ratings (hypothesis)
- **Role-specific suggestions**: ADC vs Jungle receive different Vision advice
- **Tone customization**: Competitive players get concise, data-heavy feedback; casual players get friendly, explanatory guidance
- **Persistent weakness prioritization**: Users with ongoing Vision issues see Vision suggestions first, even if other dimensions had larger gaps in current match

---

## Architecture Diagram

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        V2.2 Personalization Flow                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

  Discord User
      ‚îÇ
      ‚îÇ /settings command (set tone, role)
      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   CLI 1      ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ /user_preferences endpoint
‚îÇ  (Frontend)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ
      ‚îÇ Store preferences
      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  CLI 2 (Backend) - UserProfileService                            ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  1. Receive /jiangli command                                    ‚îÇ
‚îÇ  2. Load/Create V22UserProfile for user                         ‚îÇ
‚îÇ  3. Pass profile to PersonalizationService                      ‚îÇ
‚îÇ  4. PersonalizationService:                                     ‚îÇ
‚îÇ     ‚îú‚îÄ Select prompt template (competitive/casual)              ‚îÇ
‚îÇ     ‚îú‚îÄ Generate user context (persistent weakness, role, etc.)  ‚îÇ
‚îÇ     ‚îî‚îÄ Inject context into V2.1 prompt                          ‚îÇ
‚îÇ  5. Call Gemini LLM with personalized prompt                    ‚îÇ
‚îÇ  6. Return V21PrescriptiveAnalysisReport                        ‚îÇ
‚îÇ  7. Update user profile with new match data                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ
      ‚îÇ V21PrescriptiveAnalysisReport (same as V2.1)
      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   CLI 1      ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ Render suggestions (no change from V2.1)
‚îÇ  (Frontend)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Data Flow

### Phase 1: User Preference Configuration (CLI 1 ‚Üí CLI 2)

**CLI 1 Task**: Implement `/settings` command

```python
# CLI 1: src/contracts/discord_interactions.py

class UserPreferencesModal(discord.ui.Modal):
    """Modal for user to configure V2.2 preferences."""

    preferred_tone = discord.ui.TextInput(
        label="ÂàÜÊûêËØ≠Ê∞î (Analysis Tone)",
        placeholder="competitive (Á´ûÊäÄÂûã) Êàñ casual (‰ºëÈó≤Âûã)",
        required=False,
        default="casual"
    )

    preferred_role = discord.ui.TextInput(
        label="‰∏ªË¶Å‰ΩçÁΩÆ (Primary Role)",
        placeholder="Top, Jungle, Mid, ADC, Support, Êàñ Fill",
        required=False,
    )

    async def on_submit(self, interaction: discord.Interaction):
        # Call CLI 2 API to save preferences
        await backend_api.save_user_preferences(
            discord_user_id=interaction.user.id,
            preferred_tone=self.preferred_tone.value,
            preferred_role=self.preferred_role.value,
        )
        await interaction.response.send_message(
            "‚úÖ ÂÅèÂ•ΩËÆæÁΩÆÂ∑≤‰øùÂ≠òÔºÅ‰∏ãÊ¨°ÂàÜÊûêÂ∞ÜÊ†πÊçÆ‰Ω†ÁöÑÂÅèÂ•ΩÂÆöÂà∂„ÄÇ",
            ephemeral=True
        )
```

**CLI 2 Task**: Implement `/user_preferences` API endpoint

```python
# CLI 2: src/api/user_profile.py

from fastapi import APIRouter, Depends
from src.contracts.v22_user_profile import V22UserPreferences

router = APIRouter(prefix="/api/v2.2", tags=["user_profile"])

@router.post("/user_preferences")
async def save_user_preferences(
    discord_user_id: str,
    preferences: V22UserPreferences,
    db: Database = Depends(get_database),
):
    """Save or update user's explicit preferences from /settings command."""

    # Upsert preferences in user_profiles table
    await db.upsert_user_preferences(
        discord_user_id=discord_user_id,
        preferences=preferences.model_dump()
    )

    return {"status": "success", "message": "Preferences saved"}
```

---

### Phase 2: Profile Building & Incremental Updates (CLI 2)

**Task 2.1**: Implement `UserProfileService`

```python
# CLI 2: src/core/services/user_profile_service.py

from datetime import datetime, UTC
from src.contracts.v22_user_profile import (
    V22UserProfile,
    V22PerformanceTrends,
    V22ChampionProfile,
    V22UserClassification,
    V22ProfileUpdateEvent,
)


class UserProfileService:
    """Service for building and maintaining V2.2 user profiles."""

    def __init__(self, database, riot_api_adapter):
        self.db = database
        self.riot_api = riot_api_adapter

    async def get_or_create_profile(
        self,
        discord_user_id: str,
        puuid: str,
    ) -> V22UserProfile:
        """Load existing profile or create new one with defaults.

        Returns:
            V22UserProfile with latest data
        """
        # Try to load from database
        existing_profile = await self.db.load_user_profile(discord_user_id)

        if existing_profile:
            return V22UserProfile.model_validate(existing_profile)

        # Create new profile with defaults
        new_profile = V22UserProfile(
            discord_user_id=discord_user_id,
            puuid=puuid,
            total_matches_analyzed=0,
            last_updated=datetime.now(UTC).isoformat(),
        )

        # Save to database
        await self.db.save_user_profile(
            discord_user_id=discord_user_id,
            profile_data=new_profile.model_dump()
        )

        return new_profile

    async def update_profile_after_match(
        self,
        update_event: V22ProfileUpdateEvent,
    ) -> V22UserProfile:
        """Incrementally update user profile after new match analysis.

        This is called from analyze_team_task after V2.1 analysis completes.
        """
        # Load current profile
        profile = await self.get_or_create_profile(
            discord_user_id=update_event.discord_user_id,
            puuid=update_event.puuid,
        )

        # Update champion profile
        profile = await self._update_champion_profile(profile, update_event)

        # Update performance trends (requires last 20 matches)
        profile = await self._update_performance_trends(profile, update_event)

        # Update classification (if ranked tier changed)
        profile = await self._update_classification(profile)

        # Update metadata
        profile.total_matches_analyzed += 1
        profile.last_updated = datetime.now(UTC).isoformat()

        # Persist updated profile
        await self.db.save_user_profile(
            discord_user_id=profile.discord_user_id,
            profile_data=profile.model_dump()
        )

        return profile

    async def _update_champion_profile(
        self,
        profile: V22UserProfile,
        update_event: V22ProfileUpdateEvent,
    ) -> V22UserProfile:
        """Update champion play counts and role distribution."""

        # Update champion counts
        champion = update_event.played_champion
        current_count = profile.champion_profile.champion_play_counts.get(champion, 0)
        profile.champion_profile.champion_play_counts[champion] = current_count + 1

        # Update role counts
        role = update_event.played_role
        current_role_count = profile.champion_profile.role_distribution.get(role, 0)
        profile.champion_profile.role_distribution[role] = current_role_count + 1

        # Recalculate top 3 champions
        sorted_champions = sorted(
            profile.champion_profile.champion_play_counts.items(),
            key=lambda x: x[1],
            reverse=True
        )
        profile.champion_profile.top_3_champions = [
            champ for champ, _ in sorted_champions[:3]
        ]

        # Infer primary role (‚â•40% threshold)
        total_matches = sum(profile.champion_profile.role_distribution.values())
        if total_matches >= 5:  # Minimum 5 matches for inference
            for role, count in profile.champion_profile.role_distribution.items():
                if count / total_matches >= 0.4:
                    profile.champion_profile.inferred_primary_role = role
                    break
            else:
                profile.champion_profile.inferred_primary_role = "Fill"

        return profile

    async def _update_performance_trends(
        self,
        profile: V22UserProfile,
        update_event: V22ProfileUpdateEvent,
    ) -> V22UserProfile:
        """Update performance trends from last 20 matches."""

        # Fetch last 20 match analysis results from database
        recent_matches = await self.db.get_recent_match_analyses(
            puuid=profile.puuid,
            limit=20
        )

        if len(recent_matches) < 5:
            # Insufficient data for trends
            profile.performance_trends = None
            return profile

        # Calculate average scores
        avg_scores = {
            "Combat": sum(m["dimension_scores"]["Combat"] for m in recent_matches) / len(recent_matches),
            "Economy": sum(m["dimension_scores"]["Economy"] for m in recent_matches) / len(recent_matches),
            "Vision": sum(m["dimension_scores"]["Vision"] for m in recent_matches) / len(recent_matches),
            "Objective Control": sum(m["dimension_scores"]["Objective Control"] for m in recent_matches) / len(recent_matches),
            "Teamplay": sum(m["dimension_scores"]["Teamplay"] for m in recent_matches) / len(recent_matches),
        }

        # Identify persistent weak dimension (below team avg in ‚â•70% of matches)
        dimension_below_avg_counts = {dim: 0 for dim in avg_scores.keys()}

        for match in recent_matches:
            for dim in avg_scores.keys():
                if match["dimension_scores"][dim] < match["team_avg_scores"][dim]:
                    dimension_below_avg_counts[dim] += 1

        persistent_weak_dim = None
        weak_dim_frequency = None

        for dim, below_count in dimension_below_avg_counts.items():
            frequency = below_count / len(recent_matches)
            if frequency >= 0.7:
                persistent_weak_dim = dim
                weak_dim_frequency = frequency
                break  # Only track the most frequent weakness

        # Calculate win rate
        wins = sum(1 for m in recent_matches if m["match_result"] == "victory")
        recent_win_rate = wins / len(recent_matches)

        # Update profile
        profile.performance_trends = V22PerformanceTrends(
            avg_combat_score=avg_scores["Combat"],
            avg_economy_score=avg_scores["Economy"],
            avg_vision_score=avg_scores["Vision"],
            avg_objective_control_score=avg_scores["Objective Control"],
            avg_teamplay_score=avg_scores["Teamplay"],
            persistent_weak_dimension=persistent_weak_dim,
            weak_dimension_frequency=weak_dim_frequency,
            recent_win_rate=recent_win_rate,
        )

        return profile

    async def _update_classification(
        self,
        profile: V22UserProfile,
    ) -> V22UserProfile:
        """Update user classification (skill level, player type)."""

        # Fetch ranked tier from Riot API
        try:
            ranked_data = await self.riot_api.get_ranked_stats(profile.puuid)
            ranked_tier = ranked_data.get("tier", "UNRANKED")
        except Exception:
            ranked_tier = None

        # Infer skill level from ranked tier
        if ranked_tier in ["IRON", "BRONZE"]:
            skill_level = "beginner"
        elif ranked_tier in ["SILVER", "GOLD"]:
            skill_level = "intermediate"
        elif ranked_tier:  # PLATINUM, DIAMOND, MASTER, etc.
            skill_level = "advanced"
        else:
            skill_level = "intermediate"  # Default

        # Calculate matches per week (from last 28 days)
        matches_last_28_days = await self.db.get_match_count_in_period(
            puuid=profile.puuid,
            days=28
        )
        matches_per_week = matches_last_28_days / 4

        # Infer player type
        is_competitive = (
            matches_per_week >= 5
            and ranked_tier in ["GOLD", "PLATINUM", "DIAMOND", "MASTER", "GRANDMASTER", "CHALLENGER"]
        )
        player_type = "competitive" if is_competitive else "casual"

        # Update profile
        profile.classification = V22UserClassification(
            skill_level=skill_level,
            player_type=player_type,
            ranked_tier=ranked_tier,
            matches_per_week=matches_per_week,
        )

        return profile
```

---

### Phase 3: Personalized Analysis Generation (CLI 2 Integration)

**Task 3.1**: Modify `analyze_team_task` to use `PersonalizationService`

```python
# CLI 2: src/tasks/team_analysis_task.py

from src.core.services.personalization_service import PersonalizationService
from src.core.services.user_profile_service import UserProfileService
from src.contracts.v22_user_profile import V22ProfileUpdateEvent

@celery_app.task(name="analyze_team")
async def analyze_team_task(
    match_id: str,
    puuid: str,
    discord_user_id: str,
    enable_v21: bool = True,
    enable_v22: bool = False,  # Feature flag for V2.2
):
    """Enhanced analyze_team_task with V2.2 personalization support."""

    # ... (existing V1 + V2.1 analysis logic)

    if enable_v22:
        # --- V2.2 PERSONALIZATION FLOW ---

        # Step 1: Load or create user profile
        user_profile_service = UserProfileService(database, riot_api_adapter)
        user_profile = await user_profile_service.get_or_create_profile(
            discord_user_id=discord_user_id,
            puuid=puuid,
        )

        # Step 2: Generate personalized V2.1 analysis
        personalization_service = PersonalizationService(
            prompt_templates_dir=Path("src/prompts")
        )

        report = await personalization_service.generate_personalized_analysis(
            user_profile=user_profile,
            analysis_input=v21_input,
            llm_adapter=gemini_adapter,
        )

        # Step 3: Update user profile after match
        update_event = V22ProfileUpdateEvent(
            discord_user_id=discord_user_id,
            puuid=puuid,
            match_id=match_id,
            match_result=v21_input.match_result,
            played_role=player_role,
            played_champion=v21_input.champion_name,
            dimension_scores={
                "Combat": combat_score,
                "Economy": economy_score,
                "Vision": vision_score,
                "Objective Control": obj_control_score,
                "Teamplay": teamplay_score,
            },
            team_avg_scores=team_avg_scores,
            analyzed_at=datetime.now(UTC).isoformat(),
        )

        await user_profile_service.update_profile_after_match(update_event)

    elif enable_v21:
        # Baseline V2.1 analysis (no personalization)
        report = await gemini_adapter.generate_prescriptive_analysis_v21(
            input_data=v21_input
        )

    # ... (store report, return to CLI 1)
```

**Task 3.2**: Add `generate_prescriptive_analysis_v22` method to `GeminiLLMAdapter`

```python
# CLI 2: src/adapters/gemini_llm.py

class GeminiLLMAdapter:
    """Enhanced Gemini adapter with V2.2 personalization support."""

    async def generate_prescriptive_analysis_v22(
        self,
        input_data: V21PrescriptiveAnalysisInput,
        prompt_template: str,  # From PersonalizationService
        user_context: str,     # From PersonalizationService
    ) -> V21PrescriptiveAnalysisReport:
        """Generate V2.2 personalized prescriptive analysis.

        Args:
            input_data: V2.1 analysis input (weak dimensions + evidence)
            prompt_template: Selected prompt template (competitive/casual)
            user_context: User profile context for injection

        Returns:
            V21PrescriptiveAnalysisReport (same output contract as V2.1)
        """

        # Format prompt with user context
        formatted_prompt = prompt_template.format(
            user_profile_context=user_context,
            summoner_name=input_data.summoner_name,
            champion_name=input_data.champion_name,
            match_result=input_data.match_result,
            overall_score=input_data.overall_score,
            weak_dimensions_json=json.dumps(
                [dim.model_dump() for dim in input_data.weak_dimensions],
                ensure_ascii=False,
                indent=2
            ),
        )

        # Call Gemini with JSON Mode (same as V2.1)
        response = await self.client.generate_content(
            prompt=formatted_prompt,
            response_mime_type="application/json",
            response_schema=V21PrescriptiveAnalysisReport,
        )

        # Parse and validate
        report = V21PrescriptiveAnalysisReport.model_validate_json(
            response.text
        )

        # Add metadata
        report.llm_input_tokens = response.usage_metadata.input_tokens
        report.llm_output_tokens = response.usage_metadata.output_tokens
        report.algorithm_version = "v2.2"  # Track V2.2 usage

        return report
```

---

## Integration Tasks

### CLI 1 (Frontend) Tasks

| Task ID | Description | Estimated Effort | Dependencies |
|---------|-------------|------------------|--------------|
| CLI1-V2.2-T1 | Implement `/settings` command with modal for preference configuration | 2 days | None |
| CLI1-V2.2-T2 | Add API client method for `POST /api/v2.2/user_preferences` | 0.5 days | CLI2-V2.2-T1 |
| CLI1-V2.2-T3 | Update `/help` command documentation to mention `/settings` | 0.5 days | CLI1-V2.2-T1 |

**Total CLI 1 Effort**: 3 days

---

### CLI 2 (Backend) Tasks

| Task ID | Description | Estimated Effort | Dependencies |
|---------|-------------|------------------|--------------|
| CLI2-V2.2-T1 | Implement `POST /api/v2.2/user_preferences` endpoint | 1 day | None |
| CLI2-V2.2-T2 | Implement `UserProfileService` (profile building & incremental updates) | 4 days | None |
| CLI2-V2.2-T3 | Add `generate_prescriptive_analysis_v22` method to `GeminiLLMAdapter` | 1 day | None |
| CLI2-V2.2-T4 | Modify `analyze_team_task` to integrate `PersonalizationService` | 2 days | CLI2-V2.2-T2, CLI2-V2.2-T3 |
| CLI2-V2.2-T5 | Database migration: Add `user_profiles` table | 1 day | None |
| CLI2-V2.2-T6 | Deploy V2.2 prompt templates to production | 0.5 days | None |

**Total CLI 2 Effort**: 9.5 days (~2 weeks)

---

## Testing Strategy

### Unit Tests

**Test `PersonalizationService.select_prompt_template`**:
```python
def test_select_prompt_template_explicit_preference():
    """User explicitly set 'competitive' in /settings."""
    profile = V22UserProfile(
        preferences=V22UserPreferences(preferred_analysis_tone="competitive"),
        classification=V22UserClassification(player_type="casual"),
        # ... other fields
    )

    service = PersonalizationService(prompt_templates_dir=Path("src/prompts"))
    template = service.select_prompt_template(profile)

    assert template == "v22_coaching_competitive.txt"


def test_select_prompt_template_inferred_player_type():
    """User didn't set preference, infer from player_type."""
    profile = V22UserProfile(
        preferences=V22UserPreferences(preferred_analysis_tone=None),
        classification=V22UserClassification(player_type="casual"),
        # ... other fields
    )

    service = PersonalizationService(prompt_templates_dir=Path("src/prompts"))
    template = service.select_prompt_template(profile)

    assert template == "v22_coaching_casual.txt"
```

**Test `PersonalizationService.generate_user_context`**:
```python
def test_generate_user_context_with_persistent_weakness():
    """Generate context mentioning persistent Vision weakness."""
    profile = V22UserProfile(
        champion_profile=V22ChampionProfile(inferred_primary_role="Jungle"),
        performance_trends=V22PerformanceTrends(
            avg_vision_score=45.2,
            persistent_weak_dimension="Vision",
            weak_dimension_frequency=0.75,
            # ... other fields
        ),
        # ... other fields
    )

    service = PersonalizationService(prompt_templates_dir=Path("src/prompts"))
    context = service.generate_user_context(profile, mock_v21_input)

    assert "Jungle ‰ΩçÁΩÆÁé©ÂÆ∂" in context
    assert "Vision Áª¥Â∫¶ÂæóÂàÜÊåÅÁª≠ÂÅè‰Ωé" in context
    assert "Âπ≥Âùá 45.2 ÂàÜ" in context
    assert "75% ÁöÑÊØîËµõ‰∏≠‰Ωé‰∫éÈòü‰ºçÂπ≥ÂùáÊ∞¥Âπ≥" in context
```

**Test `UserProfileService._update_performance_trends`**:
```python
@pytest.mark.asyncio
async def test_identify_persistent_weak_dimension():
    """Identify Vision as persistent weakness (below team avg in 15/20 matches)."""

    # Mock 20 matches where Vision is below team avg in 15 matches (75%)
    mock_matches = [
        {
            "dimension_scores": {"Vision": 40, "Combat": 80, ...},
            "team_avg_scores": {"Vision": 65, "Combat": 75, ...},
            "match_result": "defeat",
        }
        for _ in range(15)  # Vision below avg
    ] + [
        {
            "dimension_scores": {"Vision": 70, "Combat": 80, ...},
            "team_avg_scores": {"Vision": 65, "Combat": 75, ...},
            "match_result": "victory",
        }
        for _ in range(5)  # Vision above avg
    ]

    service = UserProfileService(mock_database, mock_riot_api)
    mock_database.get_recent_match_analyses.return_value = mock_matches

    profile = V22UserProfile(puuid="test-puuid", ...)
    updated_profile = await service._update_performance_trends(profile, mock_event)

    assert updated_profile.performance_trends.persistent_weak_dimension == "Vision"
    assert updated_profile.performance_trends.weak_dimension_frequency == 0.75
```

---

### Integration Tests

**Test End-to-End V2.2 Flow**:
```python
@pytest.mark.asyncio
async def test_e2e_v22_personalized_analysis():
    """E2E test: /jiangli command with V2.2 personalization enabled."""

    # Setup: Create user with persistent Vision weakness
    user_profile = await create_test_user_profile(
        discord_user_id="test_user",
        puuid="test_puuid",
        persistent_weak_dimension="Vision",
        preferred_tone="competitive",
    )

    # Execute: Trigger analysis with enable_v22=True
    result = await analyze_team_task(
        match_id="NA1_12345",
        puuid="test_puuid",
        discord_user_id="test_user",
        enable_v22=True,
    )

    # Verify: Report should mention persistent Vision weakness
    report = result["v21_report"]
    assert report.algorithm_version == "v2.2"

    # Find Vision suggestion (should be prioritized)
    vision_suggestions = [
        s for s in report.improvement_suggestions if s.dimension == "Vision"
    ]
    assert len(vision_suggestions) >= 1

    # Verify issue mentions historical trend
    vision_issue = vision_suggestions[0].issue_identified
    assert "ÊúÄËøë20Âú∫ÊØîËµõ" in vision_issue or "ÊåÅÁª≠" in vision_issue
```

---

## Rollout Plan

### Phase 1: Internal Testing (Week 1)

- **Target**: CLI development team only
- **Configuration**: `enable_v22=True` for specific Discord user IDs
- **Validation**:
  - User profiles are correctly built and updated
  - Prompt templates are selected correctly (competitive vs casual)
  - User context injection works as expected

### Phase 2: Opt-In Beta (Week 2-3)

- **Target**: 20 volunteers from Discord community
- **Configuration**: Add beta testers to allowlist
- **Validation**:
  - Collect feedback on tone appropriateness
  - Monitor helpfulness ratings (should improve by ‚â•5pp)
  - Check for any LLM hallucination or incorrect context injection

### Phase 3: A/B Test (Week 4-5)

- **Target**: 20% of all users (hash-based cohort)
- **Configuration**: A/B test framework (`algorithm_version` = "v2.1" vs "v2.2")
- **Validation**:
  - Compare helpfulness ratings (V2.2 should beat V2.1 by ‚â•5pp)
  - Compare actionability ratings (V2.2 should maintain ‚â•75%)
  - Monitor token cost increase (target: ‚â§30% increase)

### Phase 4: Full Rollout (Week 6)

- **Target**: 100% of users (if A/B test succeeds)
- **Configuration**: Set `enable_v22=True` as default

---

## Success Criteria

| Metric | V2.1 Baseline | V2.2 Target | Measurement Method |
|--------|---------------|-------------|---------------------|
| **Helpfulness Rate** | 72% | ‚â•77% (+5pp) | `V21SuggestionFeedback.is_helpful` |
| **Actionability Rate** | 75% | ‚â•75% (maintain) | `V21SuggestionFeedback.is_actionable` |
| **Token Cost Increase** | Baseline | ‚â§30% | `llm_input_tokens + llm_output_tokens` |
| **User Engagement** | Baseline | +15% feedback comment length | Avg `feedback_comment` length |
| **Profile Coverage** | N/A | ‚â•80% users have profiles | Users with `total_matches_analyzed ‚â• 5` |

### Decision Matrix

| Helpfulness | Actionability | Token Cost | Decision |
|-------------|---------------|------------|----------|
| +5pp | ‚â•75% | ‚â§30% | ‚úÖ PROMOTE V2.2 TO 100% |
| +3-5pp | ‚â•75% | ‚â§30% | üü° CONDITIONAL PROMOTION (monitor 2 more weeks) |
| <+3pp | <75% | >30% | ‚ùå ROLLBACK TO V2.1 |
| +5pp | ‚â•75% | >30% | üü° OPTIMIZE PROMPTS (reduce verbosity) |

---

## Handoff Checklist

### CLI 4 (The Lab) Deliverables ‚úÖ

- [x] `src/contracts/v22_user_profile.py` - Complete data contracts
- [x] `src/core/services/personalization_service.py` - PersonalizationService implementation
- [x] `src/prompts/v22_coaching_competitive.txt` - Competitive prompt template
- [x] `src/prompts/v22_coaching_casual.txt` - Casual prompt template
- [x] `docs/V2.2_ENGINEERING_INTEGRATION_GUIDE.md` - This document

### CLI 2 (Backend) Acceptance Criteria

- [ ] `UserProfileService` implemented and tested
- [ ] `POST /api/v2.2/user_preferences` endpoint deployed
- [ ] `analyze_team_task` modified to support `enable_v22` flag
- [ ] `GeminiLLMAdapter.generate_prescriptive_analysis_v22` method added
- [ ] Database migration completed (`user_profiles` table created)
- [ ] Prompt templates deployed to production environment
- [ ] Unit tests pass (‚â•80% coverage for new code)
- [ ] Integration tests pass (E2E V2.2 flow validated)

### CLI 1 (Frontend) Acceptance Criteria

- [ ] `/settings` command implemented with preference modal
- [ ] API integration for saving user preferences completed
- [ ] `/help` documentation updated to mention `/settings`

### CLI 3 (DevOps) Monitoring Setup

- [ ] Add metric: `v22_profile_build_latency_ms` (target: <500ms)
- [ ] Add metric: `v22_prompt_injection_success_rate` (target: 100%)
- [ ] Add alert: `v22_token_cost_spike` (if >50% increase over V2.1)
- [ ] Add dashboard: V2.2 vs V2.1 A/B test comparison

---

## Estimated Timeline

| Phase | Duration | Start Date | End Date |
|-------|----------|------------|----------|
| CLI 2 Implementation | 2 weeks | 2025-10-07 | 2025-10-18 |
| CLI 1 Implementation | 3 days | 2025-10-07 | 2025-10-09 |
| Internal Testing | 1 week | 2025-10-21 | 2025-10-25 |
| Opt-In Beta | 2 weeks | 2025-10-28 | 2025-11-08 |
| A/B Test | 2 weeks | 2025-11-11 | 2025-11-22 |
| Full Rollout | 1 week | 2025-11-25 | 2025-11-29 |

**Total Time to Production**: ~8 weeks from handoff

---

## Questions & Support

**For CLI 2 Implementation Questions**: Contact CLI 4 (The Lab) with tag `[V2.2-Backend]`
**For CLI 1 Implementation Questions**: Contact CLI 4 (The Lab) with tag `[V2.2-Frontend]`
**For Research Context**: Review `notebooks/v2.2_personalization.ipynb`

---

**Engineering Handoff Status**: ‚úÖ Ready for CLI 2 & CLI 1 Acceptance
**Confidence Level**: High (comprehensive research + production-ready code)
**Estimated V2.2 ROI**: +5-10pp improvement in helpfulness ratings, +15% user engagement
